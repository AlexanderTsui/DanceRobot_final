# 舞蹈机器人主控系统产品设计文档 (PDD)

---

## 1. 概述

### 1.1. 项目目标
本项目旨在开发一个舞蹈机器人的主控系统。该系统作为机器人的“大脑”，负责整合视觉、语音和音乐识别功能，控制机器人的行为模式，并与电控部分进行精确通信，实现复杂的交互与表演任务。

### 1.2. 系统架构
本系统由主控单元、电控单元、视觉识别、语音识别及音乐识别五大核心模块组成。

- **主控单元 (MCU)**: 系统的核心，负责接收外部指令和各传感器模块信息，进行决策，并向电控单元发送控制指令。
- **电控单元 (ECU)**: 系统的执行者，负责接收主控指令，驱动电机完成机器人具体动作。
- **视觉识别子系统**: 通过摄像头捕捉环境中的人体动作，并将识别结果上报主控。
- **语音识别子系统**: 通过外置语音模块识别语音命令，并将结果上报主控。
- **音乐识别子系统**: 通过麦克风采集并识别预设的音乐片段。

---

## 2. 功能需求

### 2.1. 主模式切换
主控系统通过专用串口接收外部指令，以切换机器人的工作模式。

| 串口接收值 | 对应模式 | 描述 |
| :--- | :--- | :--- |
| **"1"** | 语音识别模式 | 机器人响应外置模块识别到的语音命令。 |
| **"2"** | 视觉识别模式 | 机器人跟随摄像头捕捉到的人体动作。 |
| **"3"** | 舞蹈模式 | 机器人根据识别到的特定音乐表演预设舞蹈。 |

### 2.2. 语音识别模式 (模式 1)
在此模式下，机器人通过外置的专用模块接收语音指令。

**工作流程:**
1.  **启动监听**: 主控进入模式1，开始监听来自外置语音模块的串口数据。
2.  **指令转发**: 语音模块独立完成识别。当识别到有效指令时，通过串口发送给主控。
3.  主控接收到数据后，**不进行任何解析**，直接通过与电控单元连接的串口进行 **原文转发**。
4.  电控单元接收到指令后，自行解析并执行相应动作。

### 2.3. 视觉识别模式 (模式 2)
在此模式下，机器人实时模仿人的动作。

**工作流程:**
1.  **启动识别**: 主控进入模式2，启动视觉识别算法，持续分析摄像头画面。
2.  **发送结果**: 当连续识别到稳定姿态后，主控立即通过串口将动作指令发送给电控单元。
3.  **可靠传输**: 指令通过一个带重试机制的函数（`send_command_with_retry`）发送，确保指令能可靠地送达ECU。

**姿态分类逻辑**
- **1. 大字站 (DaZiZhan)**
核心逻辑: 身体和四肢完全展开，形成一个“大”字。
判断规则:
双臂伸直: 左、右臂的 肩-肘-腕 角度均大于 160 度。
双腿伸直: 左、右腿的 髋-膝-踝 角度均大于 160 度。
手臂打开:
主要条件: 左、右手腕的 y 坐标与对应肩膀的 y 坐标非常接近（例如，abs(wrist.y - shoulder.y) < 0.1）。
辅助条件: 左、右 髋-肩-腕 的角度均在 70-110 度之间（大致90度）。
双腿分开: 双脚脚踝之间的水平距离 abs(left_ankle.x - right_ankle.x) 明显大于双肩之间的水平距离 abs(left_shoulder.x - right_shoulder.x)（例如，大于1.2倍）。
- **2. 弓箭步 (GongJianBu)**
核心逻辑: 一腿弯一腿直，重心偏向一侧，手臂呈战斗或拉伸姿态。需要覆盖左右两种情况。
判断规则 (以左弓步为例，右腿在前弯曲):
腿部姿态:
右腿（前腿）膝盖弯曲：右髋-右膝-右踝 角度在 90-165 度之间。
左腿（后腿）伸直：左髋-左膝-左踝 角度大于 160 度。
身体展开: 双脚脚踝之间的水平距离大于肩宽。
手臂姿态:
右臂（前臂）上扬：右髋-右肩-右肘 的角度大于 90度，且右手腕 y 坐标 < 右肩膀 y 坐标。
左臂（后臂）下摆：左髋-左肩-左肘 的角度小于 90度，且左手腕 y 坐标 > 左肩膀 y 坐标。
双臂基本伸直：左、右臂的 肩-肘-腕 角度均大于 150 度。
实现注意: 在代码中需要写一个 if 判断左弓步，再写一个 elif 判断右弓步。
- **3. 举双手 (JuShuangShou)**
核心逻辑: 身体笔直站立，双手高高举过头顶。
判断规则:
身体站直:
双腿伸直：左、右腿的 髋-膝-踝 角度均大于 160 度。
双腿并拢：双脚脚踝之间的水平距离小于肩宽的 1.1 倍。
手臂高举:
主要条件: 左、右手腕的 y 坐标均小于鼻子 (NOSE) 的 y 坐标。
辅助条件: 左、右肘部的 y 坐标也均小于对应肩膀的 y 坐标。
手臂打开: 左、右 髋-肩-肘 的角度均大于 90 度。
- **4. 蹲下 (DunXia)**
核心逻辑: 身体半蹲，双臂水平伸向身体的一侧，呈防御姿态。此逻辑经过强化，可兼容正面、侧面等多种拍摄角度。
判断规则:
1.  **基础姿态 (必须满足):**
    *   **躯干可见**: 至少能识别到单侧的“肩-髋”连线。
    *   **腿部半蹲**: 所有可见的腿，其“髋-膝-踝”角度均在 70-160 度之间。至少有一条腿可见。
    *   **手臂伸直**: 所有可见的手臂，其“肩-肘-腕”角度均大于 150 度。至少有一条手臂可见。
2.  **核心约束 (全部通过才算成功):**
    *   **动态中心线**:
        *   如果双肩双髋可见，中心线为双髋x坐标的平均值。
        *   如果仅一侧可见，则以可见侧的髋关节x坐标为中心线。
    *   **手臂同向**: 所有可见手臂的肘部和手腕，其x坐标必须 **全部** 在动态中心线的同一侧（要么全在左，要么全在右）。
    *   **手臂同高 (仅当双肩可见时检查)**: 所有可见手腕的y坐标，与双肩y坐标的平均值差异在一个容差范围内（例如，0.5倍肩宽）。
    *   **双腿并拢 (仅当双腿均可见时检查)**: 双脚踝的水平距离不应超过肩宽。
实现注意: 该逻辑通过分步检查和动态设定基准点，来处理因摄像头角度造成的关节点遮挡问题。

- **5. 比爱心 (BiAiXin)**
核心逻辑: 身体重心下移，双脚宽距站立，一腿弯曲作为支撑，另一腿向侧方伸直，同时双手在头顶比心。这是一个结合了力量、柔韧性和平衡的姿态。
判断规则 (以左腿弯曲支撑，右腿向侧方伸直为例):
腿部姿态:
双脚宽站: 双脚脚踝之间的水平距离 abs(left_ankle.x - right_ankle.x) 明显大于肩宽（例如，大于1.5倍）。
支撑腿弯曲: 左腿的 髋-膝-踝 角度在 90-165度 之间。
伸出腿伸直: 右腿的 髋-膝-踝 角度大于 160度。
双脚着地 (隐式条件): 两个脚踝的 y 坐标应大致相等 abs(left_ankle.y - right_ankle.y) 小于一个较小的阈值。
手臂姿态 (比心): (这部分的逻辑保持不变)
双手高举: 左、右手腕的 y 坐标均小于双眼 (EYE) 的 y 坐标。
双手靠近: 左、右手腕之间的距离小于双肩之间的距离。
手肘弯曲: 左、右臂的 肩-肘-腕 角度均在 70-130 度之间。
大臂抬起: 左、右 髋-肩-肘 的角度均大于 90 度。
实现注意: if/elif 判断是左腿站立还是右腿站立。
- **6. 俯卧撑 (FuWoCheng)**
核心逻辑: 身体保持一条直线，由手臂支撑，面向地面。此动作强依赖于用户侧对摄像头。
判断规则:
身体成直线:
主要条件: 肩-髋-膝 角度和 髋-膝-踝 角度均大于 160 度。
辅助条件: 肩、髋、踝的 y 坐标非常接近，表明身体是水平的。例如 abs(shoulder.y - hip.y) 和 abs(hip.y - ankle.y) 都小于某个小阈值（如0.15）。
手臂支撑:
左、右手腕的 y 坐标大于对应肩膀的 y 坐标。
左、右手腕的 x 坐标在对应肩膀的 x 坐标附近或略靠前。
头部姿态: 鼻子的 y 坐标与肩膀的 y 坐标基本持平。

**通信协议:**
- **主控 -> 电控**: 动作指令 (格式待定, e.g., `ACTION_ID:001`)
- **电控 -> 主控**: 握手信号 (字符串: `"OK"`, `"START"`)

### 2.4. 舞蹈模式 (模式 3)
在此模式下，机器人根据音乐表演预设的舞蹈。

**工作流程:**
1.  **启动识别 (异步)**: 主控进入模式3，在后台线程中启动音乐识别流程，通过麦克风采集10秒环境音频。主循环不被阻塞。
2.  **音乐匹配**: 后台线程对音频进行分析，与预设的**五段**音乐进行匹配。
3.  **发送编号**: 识别成功后，后台线程将结果放入一个线程安全的队列。主线程在轮询时从队列中获取唯一的音乐编号（`1` 到 `5`），并将其发送给电控单元。
4.  **执行舞蹈**: 电控单元根据接收到的编号，执行对应的预设舞蹈动作序列。
5.  **自动返回**: 发送编号后，主控自动返回待机模式，等待下一次指令。

---

## 3. 非功能性需求

### 3.1. 串口通信规范
- **波特率**: 9600


### 3.2. 错误处理
- **未知指令**: 当接收到无法解析的串口数据时，系统应忽略该数据，并可选择记录日志。
- **通信中断**: 若与电控单元的通信长时间中断，主控应进入安全待机状态。

---

## 4. 系统设计与技术选型

### 4.1. 核心模型：状态机
程序采用 **状态机 (State Machine)** 作为核心设计模型。一个全局变量 `current_mode` 用于追踪并控制机器人当前所处的工作模式。主程序在一个无限循环中运行，根据 `current_mode` 的值调用相应的处理函数。

### 4.2. 通信逻辑
系统使用两个核心串口：
- **`voice_serial`**: 用于 **单向接收** 来自外置语音模块的数据。
- **`ecu_serial`**: 用于和 **电控单元 (ECU) 进行双向通信**。

所有来自ECU的指令（模式切换、状态确认）都通过 `ecu_serial` 接收，主控在主循环中优先处理。

### 4.3. 程序执行流程 (异步增强)
1.  **初始化**: 初始化所有硬件资源，进入待机模式。
2.  **主循环**:
    - **最高优先级**: 监听并处理来自`ecu_serial`的模式切换指令。
    - **轮询任务**: 根据`current_mode`执行对应模式的任务。
    - **异步处理**: 在**舞蹈模式**下，识别任务在一个独立的后台线程中执行，以确保主循环的高响应性。主线程通过队列获取识别结果，实现了**非阻塞式**的耗时任务处理。

---

## 5. 技术选型与实现
本部分取代了初版文档的“待定项”，记录项目最终的技术选型。

- **[已完成] 视觉识别技术方案**:
  - **方案**: 采用 **MediaPipe** 库的 `Pose` 模型。
  - **理由**: 性能优异，资源占用适中，API友好，非常适合在嵌入式设备或PC上进行实时人体姿态估计。

- **[已完成] 视觉识别数据格式**:
  - **格式**: 纯小写英文字符串，如 `"dazizhan"`, `"gongjianbu"`。
  - **理由**: 格式简单，便于串口传输和下位机解析。

- **[已完成] 语音指令集与格式**:
  - **方案**: 主控程序对语音指令内容**透明**。
  - **理由**: 遵循“单一职责”原则，主控不关心语音具体内容，只负责将语音模块识别到的字符串原样转发给ECU，由ECU进行解析。

- **[已完成] 音乐识别技术方案**:
  - **方案**: 采用基于 **Librosa** 库，并经过多轮迭代优化的**定制化音频指纹方案**。
  - **核心技术**:
    1.  **分段指纹库**: 将参考音乐切分为多个10秒重叠片段，进行“局部对局部”的精确匹配。
    2.  **融合特征**: 指纹同时包含**Chroma**（和声）和**MFCC**（音色）两种特征，实现多维度识别。
    3.  **独立标准化**: 对两种特征分别进行标准化处理，确保它们在计算中权重均衡。
    4.  **几何平均计分**: 分别计算两种特征的相似度，再通过几何平均合并，有效惩罚“偏科”的匹配项，极大提升了区分度。

- **[已完成] 串口通信参数**:
  - **方案**: 波特率9600, 8-N-1，超时0.1秒。
  - **理由**: 这是工业和DIY领域最常用、最稳定的串口配置之一。

- **[已完成] 通信重试机制**:
  - **方案**: 实现了一个`send_command_with_retry`函数。
  - **逻辑**: 发送指令后，在规定时间内等待ECU返回相同的内容作为确认。若超时则重试，失败3次后放弃。确保了关键指令的可靠送达。
